{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Week 3 Hands-on Lab: Building a Simplified Transformer Encoder**"
      ],
      "metadata": {
        "id": "UvODY4XYGS4s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This hands-on lab allows you to understand the Transformer architecture by implementing a basic Transformer encoder. You will learn how input embeddings, positional encodings, and feedforward layers work together in an encoder block. We will be using the Torch framework to build a simple transformer encoder."
      ],
      "metadata": {
        "id": "tV7jIspzGcIM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 1: Input Embedding and Positional Encoding**"
      ],
      "metadata": {
        "id": "UD0bA42xGnZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.\tGenerate Input Data**\n",
        "Define a sample sentence and tokenize it into a numerical format.\n"
      ],
      "metadata": {
        "id": "B-uZW8_bGvUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# Example sentence and token IDs (simplified for illustration)\n",
        "token_ids = torch.tensor([[1, 2, 3, 4, 5]])  # Tokenized sentence\n",
        "vocab_size = 10  # Vocabulary size\n",
        "embedding_dim = 8  # Embedding size"
      ],
      "metadata": {
        "id": "bulopUQ1GzrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Create an Embedding Layer**\n",
        "Implement the embedding layer to convert token IDs into dense vectors."
      ],
      "metadata": {
        "id": "4khCooiqIdHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
        "embedded_tokens = embedding_layer(token_ids)\n",
        "print(\"Embedded Tokens:\\n\", embedded_tokens)"
      ],
      "metadata": {
        "id": "LjWIeI7GIoEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.\tAdd Positional Encoding**\n",
        "Incorporate positional encoding to provide positional information to the model.\n"
      ],
      "metadata": {
        "id": "EfdPOMcpG_qJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(seq_len, embedding_dim):\n",
        "    position = np.arange(seq_len)[:, np.newaxis]\n",
        "    div_term = np.exp(np.arange(0, embedding_dim, 2) * -(np.log(10000.0) / embedding_dim))\n",
        "    pe = np.zeros((seq_len, embedding_dim))\n",
        "    pe[:, 0::2] = np.sin(position * div_term)\n",
        "    pe[:, 1::2] = np.cos(position * div_term)\n",
        "    return torch.tensor(pe, dtype=torch.float)\n",
        "\n",
        "seq_len = token_ids.size(1)\n",
        "pos_encoding = positional_encoding(seq_len, embedding_dim)\n",
        "print(\"Positional Encoding:\\n\", pos_encoding)\n"
      ],
      "metadata": {
        "id": "Mti1h0tXHDXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add the positional encoding to the embedded tokens:"
      ],
      "metadata": {
        "id": "iZm2hKp-HIxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_with_pos = embedded_tokens + pos_encoding.unsqueeze(0)\n",
        "print(\"Embedded Tokens with Positional Encoding:\\n\", embedded_with_pos)\n"
      ],
      "metadata": {
        "id": "TMwXiAIiHLm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 2: Add a Feedforward Layer**"
      ],
      "metadata": {
        "id": "wfM3VX60HQ6b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\t**Define a Feedforward Neural Network**\n",
        "Implement a simple feedforward layer as part of the encoder.\n"
      ],
      "metadata": {
        "id": "oUaKhCEuHViQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feedforward = nn.Sequential(\n",
        "    nn.Linear(embedding_dim, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, embedding_dim)\n",
        ")\n",
        "ff_output = feedforward(embedded_with_pos)\n",
        "print(\"Feedforward Output:\\n\", ff_output)\n"
      ],
      "metadata": {
        "id": "RIN1MxZVHZwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 3: Combine the Components into an Encoder Block**"
      ],
      "metadata": {
        "id": "xb9uak0OHcjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\t**Define the Encoder Block**\n",
        "Combine the embedding, positional encoding, and feedforward components into an encoder block.\n"
      ],
      "metadata": {
        "id": "qXVdYvwkHgdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderBlock(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(TransformerEncoderBlock, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(embedding_dim, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, embedding_dim)\n",
        "        )\n",
        "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embed = self.embedding(x)\n",
        "        pos_enc = positional_encoding(x.size(1), embed.size(2))\n",
        "        embed_with_pos = embed + pos_enc.unsqueeze(0)\n",
        "        ff_output = self.feedforward(embed_with_pos)\n",
        "        return self.layer_norm(embed_with_pos + ff_output)\n",
        "\n",
        "encoder = TransformerEncoderBlock(vocab_size, embedding_dim)\n",
        "output = encoder(token_ids)\n",
        "print(\"Encoder Output:\\n\", output)\n"
      ],
      "metadata": {
        "id": "70IMzzkPHmRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 4: Experiment with Different Inputs**\n",
        "\n",
        "* Test with Different Sentences\n",
        "Replace token_ids with new examples to observe how the encoder processes different inputs.\n",
        "* Modify Hyperparameters\n",
        "Experiment with different embedding sizes, feedforward dimensions, or positional encoding scales to see their effect on the output.\n"
      ],
      "metadata": {
        "id": "zfB-L5zlHqhV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Summary**"
      ],
      "metadata": {
        "id": "IZW4m09oIIFm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By completing this lab, you have:\n",
        "\n",
        "* Understood the role of embedding, positional encoding, and feedforward layers in the Transformer encoder.\n",
        "* Gained hands-on experience implementing a core component of the Transformer architecture.\n",
        "* Developed a deeper appreciation for the architectureâ€™s design and functionality.\n",
        "\n",
        "This lab builds foundational knowledge of the Transformer, preparing you for more advanced concepts like self-attention.\n"
      ],
      "metadata": {
        "id": "49Ko4E9cH4df"
      }
    }
  ]
}